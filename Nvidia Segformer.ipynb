{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ff4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on this https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb\n",
    "# PARAMS\n",
    "SPLIT = -1\n",
    "IMAGE_SIZE_REDUCE_FACTOR = 3\n",
    "NUM_OF_CLASSES = 35\n",
    "IMAGE_SHAPE = (1200//IMAGE_SIZE_REDUCE_FACTOR, 1920//IMAGE_SIZE_REDUCE_FACTOR)\n",
    "\n",
    "# MODEL PARAMS\n",
    "DROPOUT = 0.5\n",
    "ENCODER_BLOCKS = 4 # If changed, need to add strides, etc\n",
    "# https://huggingface.co/docs/transformers/v4.27.2/en/model_doc/segformer#transformers.SegformerConfig.depths\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.00001/5/2 # Added the over 2 because now were continuing training from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8301bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dirt': 1, 'grass': 3, 'tree': 4, 'pole': 5, 'water': 6, 'sky': 7, 'vehicle': 8, 'object': 9, 'asphalt': 10, 'building': 12, 'log': 15, 'person': 17, 'fence': 18, 'bush': 19, 'concrete': 23, 'barrier': 27, 'puddle': 31, 'mud': 33, 'rubble': 34}\n"
     ]
    }
   ],
   "source": [
    "# Load Ontology\n",
    "import pandas as pd\n",
    "\n",
    "ontology = pd.read_csv(\"Rellis-3D/ontology.csv\")[[\"class_name\", \"output_value\", \"display_color\"]].values.tolist()\n",
    "colors = {v[0]: v[2] for v in ontology}\n",
    "ontology = {v[0]: v[1] for v in ontology}\n",
    "\n",
    "# Remove extra classes\n",
    "del ontology[\"void\"]\n",
    "# del ontology[\"dirt\"]\n",
    "del ontology[\"uphill\"]\n",
    "del ontology[\"downhill\"]\n",
    "\n",
    "# Extra Ontology\n",
    "# Prob should copy elsewhere\n",
    "label2id = ontology\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Process colors\n",
    "colors = {c: (int(colors[c][1:3], 16), int(colors[c][3:5], 16), int(colors[c][5:7], 16)) for c in ontology.keys()}\n",
    "\n",
    "# Convert ontology to color map\n",
    "ontology = list(ontology.values())\n",
    "ontology = [i in ontology for i in range(NUM_OF_CLASSES)]\n",
    "\n",
    "NUM_OF_CLASSES = ontology.count(True)\n",
    "\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afcade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:23:19.589329: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-13 22:23:19.627603: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 22:23:20.172672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Code to deal with changes in files needed for segformer\n",
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def channel_first(images):\n",
    "    return np.transpose(images, axes=[0, 3, 1, 2])\n",
    "\n",
    "def convert_labels_to_argmaxes(images):\n",
    "    return np.argmax(images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc46537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process images\n",
    "files = \"Processed Data/\"\n",
    "\n",
    "with np.load(files + \"%s_%d.npz\" % (\"train\", SPLIT)) as data:\n",
    "    x_train, y_train = data[\"img_depth_ds\"].astype(np.float16), data[\"img_oh_ds\"].astype(np.float16)\n",
    "    \n",
    "with np.load(files + \"%s_%d.npz\" % (\"val\", SPLIT)) as data:\n",
    "    x_val, y_val = data[\"img_depth_ds\"].astype(np.float16), data[\"img_oh_ds\"].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d60ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3301, 400, 640, 19)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "x_train, y_train = channel_first(x_train), convert_labels_to_argmaxes(y_train)\n",
    "x_val, y_val = channel_first(x_val), convert_labels_to_argmaxes(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bfe7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setup model\n",
    "from transformers import SegformerConfig, SegformerImageProcessor\n",
    "\n",
    "config = SegformerConfig(\n",
    "                            num_channels=4,\n",
    "                            hidden_dropout_prob=DROPOUT,\n",
    "                            num_encoder_blocks=ENCODER_BLOCKS,\n",
    "                            num_labels=NUM_OF_CLASSES,\n",
    "                            id2label=id2label,\n",
    "                            label2id=label2id,\n",
    "                        )\n",
    "\n",
    "preprocessor = SegformerImageProcessor(do_resize=False,\n",
    "                                       size={\"height\": IMAGE_SHAPE[0], \"width\": IMAGE_SHAPE[1]},\n",
    "                                       do_rescale=False,\n",
    "                                       do_normalize=False,\n",
    "                                       do_reduce_labels=False\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a8f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "train = preprocessor.preprocess(x_train, segmentation_maps=y_train, return_tensors=\"np\", data_format=None) # , data_format=\"channels_first\")\n",
    "val = preprocessor.preprocess(x_val, segmentation_maps=y_val, return_tensors=\"np\", data_format=None) # , data_format=\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85313e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class streams data to the model\n",
    "# https://stackoverflow.com/a/71592809\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train = DataGenerator(train[\"pixel_values\"], train[\"labels\"].astype(np.int8), BATCH_SIZE)\n",
    "val = DataGenerator(val[\"pixel_values\"], val[\"labels\"].astype(np.int8), BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56174d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distribution strategy\n",
    "# https://www.tensorflow.org/guide/distributed_training\n",
    "\n",
    "# dist_strategy = tf.distribute.experimental.CentralStorageStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42566338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:27:53.495580: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-06-13 22:27:53.495664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22051 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:18:00.0, compute capability: 8.9\n",
      "2023-06-13 22:27:53.496290: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 1\n",
      "2023-06-13 22:27:53.496335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22266 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n",
      "2023-06-13 22:27:54.617322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-06-13 22:27:55.092919: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2023-06-13 22:27:55.092938: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2023-06-13 22:27:55.092986: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-06-13 22:27:55.118835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-13 22:27:55.190344: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1469b7870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-13 22:27:55.190361: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2023-06-13 22:27:55.190365: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-06-13 22:27:55.209566: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:641] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Setting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\n",
      "This message will only be logged once.\n",
      "2023-06-13 22:27:55.303133: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Conv._jit_compiled_convolution_op at 0x7fb1103876d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Conv._jit_compiled_convolution_op at 0x7fb0effed120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFSegformerForSemanticSegmentation.\n",
      "\n",
      "All the layers of TFSegformerForSemanticSegmentation were initialized from the model checkpoint at Saved Models/segformer-b3-depth.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFSegformerForSemanticSegmentation for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "from transformers import TFSegformerForSemanticSegmentation\n",
    "from tensorflow.keras import models, optimizers, losses\n",
    "\n",
    "# with dist_strategy.scope():\n",
    "# segformer = TFSegformerForSemanticSegmentation(config,) Want to try a pre-trained model\n",
    "# segformer = TFSegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b3-finetuned-cityscapes-1024-1024\",\n",
    "#                                                                 num_channels=3,\n",
    "#                                                                 hidden_dropout_prob=DROPOUT,\n",
    "#                                                                 num_encoder_blocks=ENCODER_BLOCKS,\n",
    "#                                                                 num_labels=NUM_OF_CLASSES,\n",
    "#                                                                 id2label=id2label,\n",
    "#                                                                 label2id=label2id,\n",
    "#                                                                 ignore_mismatched_sizes=True\n",
    "#                                                               )\n",
    "\n",
    "# previous segformer\n",
    "# segformer = TFSegformerForSemanticSegmentation.from_pretrained(\"Saved Models/segformer\")\n",
    "\n",
    "segformer = TFSegformerForSemanticSegmentation.from_pretrained(\"Saved Models/segformer-b3-depth\")\n",
    "\n",
    "# segformer = TFSegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b3\",\n",
    "#                                                                 num_channels=4,\n",
    "# #                                                                 hidden_dropout_prob=DROPOUT,\n",
    "#                                                                 num_encoder_blocks=ENCODER_BLOCKS,\n",
    "#                                                                 num_labels=NUM_OF_CLASSES,\n",
    "#                                                                 id2label=id2label,\n",
    "#                                                                 label2id=label2id,\n",
    "#                                                                 ignore_mismatched_sizes=True\n",
    "#                                                               )\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "categorical_focal = tf.keras.losses.CategoricalFocalCrossentropy()\n",
    "def sparse_categorical_focal(y_true, y_pred):\n",
    "    y_true = tf.one_hot(y_true, depth=NUM_OF_CLASSES, axis=1)\n",
    "    scale_down = 4 # y_true.shape[2] // y_pred.shape[2]\n",
    "    y_true = tf.nn.avg_pool(\n",
    "        y_true, scale_down, scale_down, \"VALID\", data_format=\"NCHW\", name=None\n",
    "    )\n",
    "    return categorical_focal(y_true, y_pred)\n",
    "\n",
    "segformer.compile(opt, loss=sparse_categorical_focal) # No loss to use default huggingface loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad8d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own metrics callback\n",
    "# Some from here (show_predictions) https://keras.io/examples/vision/segformer/\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "class MetricCallback(Callback):\n",
    "    def __init__(self, validation, patience=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.validation = validation\n",
    "        self.metrics = [  \n",
    "            metrics.SparseTopKCategoricalAccuracy(k=1, name='Top 1 Accuracy'),\n",
    "            metrics.SparseTopKCategoricalAccuracy(k=3, name='Top 3 Accuracy'),\n",
    "            metrics.SparseTopKCategoricalAccuracy(k=5, name='Top 5 Accuracy'),\n",
    "            metrics.MeanIoU(num_classes=NUM_OF_CLASSES, sparse_y_true=True, sparse_y_pred=False, name='Mean IoU')\n",
    "        ]\n",
    "        \n",
    "        # For early stopping\n",
    "        self.patience = patience\n",
    "        self.past_val_losses = []\n",
    "        self.best = None\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.run_metrics()\n",
    "        self.early_stopping()\n",
    "    \n",
    "    def early_stopping(self):\n",
    "        if self.patience:\n",
    "            best_loss = min(self.past_val_losses)\n",
    "            if best_loss == self.past_val_losses[-1]:\n",
    "                self.best_weights = self.model.get_weights()\n",
    "            elif best_loss not in self.past_val_losses[-self.patience:]:\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "            print(\"Best Val Loss: %.5f\" % best_loss)\n",
    "    \n",
    "    def upscale_logits(self, pred_masks, size, np=True):\n",
    "        pred_masks = tf.transpose(pred_masks, perm=[0, 2, 3, 1])\n",
    "            \n",
    "        pred_masks = tf.image.resize(\n",
    "            pred_masks,\n",
    "            size=size,\n",
    "            method=\"bilinear\",\n",
    "        )\n",
    "        \n",
    "        if np:\n",
    "            return pred_masks.numpy()\n",
    "        return pred_masks\n",
    "    \n",
    "    def run_metrics(self):\n",
    "        metrics_res = [[] for _ in self.metrics]\n",
    "        \n",
    "        for samples in self.validation:\n",
    "            images, masks = samples[0], samples[1]\n",
    "            pred_masks = self.model.predict(images, verbose=0).logits\n",
    "            pred_masks = self.upscale_logits(pred_masks, samples[1].shape[1:], np=False)\n",
    "            \n",
    "#             pred_masks = tf.argmax(pred_masks, axis=-1)\n",
    "            \n",
    "            for metric in self.metrics:\n",
    "                metric.update_state(y_true=masks, y_pred=pred_masks)\n",
    "            \n",
    "            # Class based metrics\n",
    "            \n",
    "        for metric in self.metrics:\n",
    "                print(\"%s: %.5f\" % (metric.name, metric.result().numpy()))\n",
    "                metric.reset_state()\n",
    "        \n",
    "        val_loss = self.model.evaluate(self.validation, verbose=0)\n",
    "        print(\"Val Loss: %.5f\" % val_loss)\n",
    "        self.past_val_losses.append(val_loss)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bcc91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:27:58.561839: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-13 22:28:46.240804: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape intf_segformer_for_semantic_segmentation/decode_head/dropout_84/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-06-13 22:28:59.698437: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - ETA: 0s - loss: 11.2174Top 1 Accuracy: 0.53652\n",
      "Top 3 Accuracy: 0.78973\n",
      "Top 5 Accuracy: 0.82476\n",
      "Mean IoU: 0.09762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:33:55.897402: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.05243\n",
      "Best Val Loss: 11.05243\n",
      "413/413 [==============================] - 386s 687ms/step - loss: 11.2174\n",
      "Epoch 2/300\n",
      "413/413 [==============================] - ETA: 0s - loss: 11.1294Top 1 Accuracy: 0.53901\n",
      "Top 3 Accuracy: 0.75966\n",
      "Top 5 Accuracy: 0.77957\n",
      "Mean IoU: 0.08984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:38:18.943554: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.00578\n",
      "Best Val Loss: 11.00578\n",
      "413/413 [==============================] - 255s 617ms/step - loss: 11.1294\n",
      "Epoch 3/300\n",
      "413/413 [==============================] - ETA: 0s - loss: 11.3259Top 1 Accuracy: 0.32682\n",
      "Top 3 Accuracy: 0.55517\n",
      "Top 5 Accuracy: 0.58233\n",
      "Mean IoU: 0.04908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:42:34.587940: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 10.91402\n",
      "Best Val Loss: 10.91402\n",
      "413/413 [==============================] - 256s 619ms/step - loss: 11.3259\n",
      "Epoch 4/300\n",
      "413/413 [==============================] - ETA: 0s - loss: 11.4632Top 1 Accuracy: 0.27308\n",
      "Top 3 Accuracy: 0.46178\n",
      "Top 5 Accuracy: 0.50942\n",
      "Mean IoU: 0.04777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:46:50.463841: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.67637\n",
      "Best Val Loss: 10.91402\n",
      "413/413 [==============================] - 255s 618ms/step - loss: 11.4632\n",
      "Epoch 5/300\n",
      "413/413 [==============================] - ETA: 0s - loss: 11.5378Top 1 Accuracy: 0.29283\n",
      "Top 3 Accuracy: 0.37985\n",
      "Top 5 Accuracy: 0.41167\n",
      "Mean IoU: 0.04359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:51:06.641426: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.29208\n",
      "Best Val Loss: 10.91402\n",
      "413/413 [==============================] - 256s 619ms/step - loss: 11.5378\n",
      "Epoch 6/300\n",
      "413/413 [==============================] - ETA: 0s - loss: 11.3155Top 1 Accuracy: 0.27142\n",
      "Top 3 Accuracy: 0.37015\n",
      "Top 5 Accuracy: 0.39707\n",
      "Mean IoU: 0.03764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:55:24.684557: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.10769\n",
      "Best Val Loss: 10.91402\n",
      "413/413 [==============================] - 259s 627ms/step - loss: 11.3155\n",
      "Epoch 7/300\n",
      "413/413 [==============================] - ETA: 0s - loss: 11.5463Top 1 Accuracy: 0.27944\n",
      "Top 3 Accuracy: 0.42792\n",
      "Top 5 Accuracy: 0.47295\n",
      "Mean IoU: 0.03899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:59:38.023321: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.56352\n",
      "Best Val Loss: 10.91402\n",
      "413/413 [==============================] - 253s 613ms/step - loss: 11.5463\n",
      "Epoch 8/300\n",
      "413/413 [==============================] - ETA: 0s - loss: 11.6172Top 1 Accuracy: 0.35884\n",
      "Top 3 Accuracy: 0.51872\n",
      "Top 5 Accuracy: 0.55219\n",
      "Mean IoU: 0.04973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 23:03:54.910893: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.37056\n",
      "Best Val Loss: 10.91402\n",
      "413/413 [==============================] - 257s 623ms/step - loss: 11.6172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb0ec45b5b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "segformer.fit(\n",
    "    train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = 300,\n",
    "    callbacks = [\n",
    "        # EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        MetricCallback(val, patience=5)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d00137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_segformer_for_semantic_segmentation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " segformer (TFSegformerMain  multiple                  44075264  \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " decode_head (TFSegformerDe  multiple                  3166483   \n",
      " codeHead)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47241747 (180.21 MB)\n",
      "Trainable params: 47240211 (180.21 MB)\n",
      "Non-trainable params: 1536 (6.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary, just to see number of neurons\n",
    "segformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ddeac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set\n",
    "with np.load(files + \"%s_%d.npz\" % (\"train\", SPLIT)) as data:\n",
    "    x_test, y_test = data[\"img_depth_ds\"].astype(np.float16), data[\"img_oh_ds\"].astype(np.float16)\n",
    "\n",
    "x_test, y_test = channel_first(x_test), convert_labels_to_argmaxes(y_test)\n",
    "test = preprocessor.preprocess(x_test, segmentation_maps=y_test, return_tensors=\"np\", data_format=None)\n",
    "\n",
    "# Create sequence\n",
    "test = DataGenerator(test[\"pixel_values\"], test[\"labels\"].astype(np.int8), BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cccc25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Accuracy: 0.26293\n",
      "Top 3 Accuracy: 0.51466\n",
      "Top 5 Accuracy: 0.55209\n",
      "Mean IoU: 0.04016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 23:13:11.732114: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 11.10847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nb2 ---\\nTop 1 Accuracy: 0.89751\\nTop 3 Accuracy: 0.99120\\nTop 5 Accuracy: 0.99471\\nMean IoU: 0.34790\\nVal Loss: 0.32299\\n\\nb3 --- Can prob improve with better hyperparams\\nTop 1 Accuracy: 0.91141\\nTop 3 Accuracy: 0.99060\\nTop 5 Accuracy: 0.99402\\nMean IoU: 0.30426\\nVal Loss: 0.27632\\n\\nb3-depth ---\\nTop 1 Accuracy: 0.91694\\nTop 3 Accuracy: 0.99749\\nTop 5 Accuracy: 0.99911\\nMean IoU: 0.46011\\nVal Loss: 0.21744\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluator = MetricCallback(test)\n",
    "\n",
    "evaluator.model = segformer\n",
    "evaluator.run_metrics()\n",
    "\n",
    "# Best stats:\n",
    "\"\"\"\n",
    "b2 ---\n",
    "Top 1 Accuracy: 0.89751\n",
    "Top 3 Accuracy: 0.99120\n",
    "Top 5 Accuracy: 0.99471\n",
    "Mean IoU: 0.34790\n",
    "Val Loss: 0.32299\n",
    "\n",
    "b3 --- Can prob improve with better hyperparams\n",
    "Top 1 Accuracy: 0.91141\n",
    "Top 3 Accuracy: 0.99060\n",
    "Top 5 Accuracy: 0.99402\n",
    "Mean IoU: 0.30426\n",
    "Val Loss: 0.27632\n",
    "\n",
    "b3-depth ---\n",
    "Top 1 Accuracy: 0.91694\n",
    "Top 3 Accuracy: 0.99749\n",
    "Top 5 Accuracy: 0.99911\n",
    "Mean IoU: 0.46011\n",
    "Val Loss: 0.21744\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f085698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 5 test images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "for original, image in zip(x_test[0:10, :3, :, :], segformer.predict(x_test[0:10]).logits):\n",
    "    image = evaluator.upscale_logits(np.expand_dims(image, axis=0), IMAGE_SHAPE)[0]\n",
    "    original = np.transpose(original, axes=[1, 2, 0])\n",
    "    colored_image = np.argmax(image, axis=-1)\n",
    "    colored_image = np.array(list(colors.values()))[colored_image]\n",
    "    plt.imshow(original.astype(np.float32))\n",
    "    plt.imshow(colored_image, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957c817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ONLY UNCOMMENT IF THIS IS THE BEST MODEL\n",
    "# # TODO: Save figures for upscaling output, run in separate upscaler notebook\n",
    "from tensorflow import device\n",
    "\n",
    "train_to_be_upscaled = segformer.predict(train, batch_size=BATCH_SIZE).logits\n",
    "val_to_be_upscaled = segformer.predict(val, batch_size=BATCH_SIZE).logits\n",
    "test_to_be_upscaled = segformer.predict(test, batch_size=BATCH_SIZE).logits\n",
    "\n",
    "with device(\"cpu:0\"):\n",
    "    train_to_be_upscaled = evaluator.upscale_logits(train_to_be_upscaled, IMAGE_SHAPE)\n",
    "    val_to_be_upscaled = evaluator.upscale_logits(val_to_be_upscaled, IMAGE_SHAPE)\n",
    "    test_to_be_upscaled = evaluator.upscale_logits(test_to_be_upscaled, IMAGE_SHAPE)\n",
    "\n",
    "\n",
    "np.savez(\"Processed Data/images_%d_predictions_%d_segformer.npz\" % (SPLIT, IMAGE_SIZE_REDUCE_FACTOR), train=train_to_be_upscaled, val=val_to_be_upscaled, test=test_to_be_upscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY UNCOMMENT IF THIS IS THE BEST MODEL\n",
    "from tensorflow import saved_model\n",
    "\n",
    "segformer.save_pretrained(\"Saved Models/segformer-b3-depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe943d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
